{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bishuprojects1610/Dog-vs-Cat/blob/master/Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "McKZf4bl3PEE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install pyDrive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sn870igH3hk6",
        "colab_type": "code",
        "outputId": "726f113f-f2e9-4449-e937-20dcd4804efc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras \n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow as tf\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "Vd-QCB8a3kls",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Kl-l_U6L37Sy",
        "colab_type": "code",
        "outputId": "90112b29-fd30-4793-ea1c-7d0c7b29469f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Gz1tyQpB8gs0",
        "colab_type": "code",
        "outputId": "d06aec6b-a89f-4e2d-c342-4376d4c0a97c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "!git clone \"https://github.com/bishuprojects1610/Dog-vs-Cat\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Dog-vs-Cat'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects:  33% (1/3)   \u001b[K\rremote: Counting objects:  66% (2/3)   \u001b[K\rremote: Counting objects: 100% (3/3)   \u001b[K\rremote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects:  33% (1/3)   \rUnpacking objects:  66% (2/3)   \rUnpacking objects: 100% (3/3)   \rUnpacking objects: 100% (3/3), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "K21dJwWyUcoO",
        "colab_type": "code",
        "outputId": "3a0e8156-7c94-4fea-dfe9-154be3045f4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "path = '/content/drive/My Drive/content/data'\n",
        "!ls '/content/drive/My Drive/content/data'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sampleSubmission.csv  test  train\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3tbEUFCbVUHf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "with zipfile .ZipFile(\"/content/drive/My Drive/content/data/test1.zip\",\"r\") as zip_ref:\n",
        "  zip_ref.extractall(\"/content/drive/My Drive/content/data/test\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ibGLF6EmZXoX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#load data\n",
        "train_data_dir = path + 'train/train'\n",
        "test_data_dir = path + 'test/test'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ksS-Ctvbfx9-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "IMG_HEIGHT = 50\n",
        "IMG_WIDTH = 50\n",
        "NUM_CHANNELS = 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tMgHVDClf3km",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from threading import current_thread, Thread, Lock\n",
        "from multiprocessing import Queue"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sqQqjYtaglW_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#initialization for thread\n",
        "batch_size = 500\n",
        "num_train_images = 25000\n",
        "num_test_images = 12500\n",
        "num_train_threads = int(num_train_images/batch_size)  # 50\n",
        "num_test_threads = int(num_test_images/batch_size)    # 25\n",
        "lock = Lock()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e2TGtNmBgwIE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#use queue to collect results from thread\n",
        "def initialize_queue():\n",
        "    queue = Queue()\n",
        "    return queue"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "proIFRL8hMLu",
        "colab_type": "code",
        "outputId": "29cba6fe-6b9f-44e2-e1a7-d14079ae3c1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "from os import listdir\n",
        "from os.path import join, basename\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "train_dir_path = path + \"/train/train\"\n",
        "test_dir_path = path + \"/test/test1\"\n",
        "train_imgs = [join(train_dir_path,f) for f in listdir(train_dir_path)]\n",
        "test_imgs = [join(test_dir_path,f) for f in listdir(test_dir_path)]\n",
        "print(len(train_imgs))\n",
        "print(len(test_imgs))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000\n",
            "12500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kWyS57JgiVbb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#one-hot encoding for image file\n",
        "def get_img_label(fpath):\n",
        "  category = fpath.split(\".\")[-3]\n",
        "  if category == \"dog\":\n",
        "    return [1,0]\n",
        "  elif category == \"cat\":\n",
        "    return [0,1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9qsMK8uJjm9c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_img_array_labels(fpaths, queue):\n",
        "  img_array = None\n",
        "  labels = []\n",
        "  for f in fpaths:\n",
        "    arr = Image.open(f)\n",
        "    arr = arr.resize((IMG_HEIGHT,IMG_WIDTH), Image.ANTIALIAS)\n",
        "    arr = np.reshape(arr, (-1, IMG_HEIGHT, IMG_WIDTH, NUM_CHANNELS))\n",
        "    if img_array is None:\n",
        "      img_array=arr\n",
        "    else:\n",
        "      img_array = np.vstack((img_array,arr))\n",
        "    labels.append(get_img_label(basename(f)))\n",
        "  labels = np.array(labels)\n",
        "  queue.put((img_array,labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zy-WkpZSll8m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#convert test images to np array\n",
        "def get_img_array(fpaths,queue):\n",
        "  img_array = None\n",
        "  for f in fpaths:\n",
        "    arr = Image.open(f)\n",
        "    arr = arr.resize((IMG_HEIGHT,IMG_WIDTH), Image.ANTIALIAS)\n",
        "    arr = np.reshape(arr, (-1, IMG_HEIGHT, IMG_WIDTH, NUM_CHANNELS))\n",
        "    if img_array is None:\n",
        "      img_array = arr\n",
        "    else:\n",
        "      img_array = np.vstack((img_array,arr))\n",
        "  queue.put(img_array)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Tk8E51pamenJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def dump_array(fname,arr):\n",
        "  with open(fname,'wb')as f:\n",
        "    pickle.dump(arr,f)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PjHiuotdmrVg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_pickled_array(fname , arr):\n",
        "  with open(fname, 'rb') as f:\n",
        "    return pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W-eIBC8Gm6hw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#use threading to combine training array and lables\n",
        "\n",
        "def get_training_data():\n",
        "  threads_list = list()\n",
        "  train_x = None\n",
        "  train_y = []\n",
        "  queue = initialize_queue()\n",
        "  \n",
        "  #loop over all threads to create\n",
        "  for thread_index in range(num_train_threads):\n",
        "    start_index = thread_index * batch_size\n",
        "    end_index = (thread_index +1) * batch_size\n",
        "    file_batch = train_imgs[start_index:end_index]\n",
        "    thread = Thread(target = get_img_array_labels, args=(file_batch, queue))\n",
        "    thread.start()\n",
        "    threads_list.append(thread)\n",
        "    \n",
        "    print(\"Thread: {}, start index: {}, end index: {}\".format(thread.name,start_index,end_index))\n",
        "  for t in threads_list:\n",
        "    t.join()\n",
        "    \n",
        "  while not queue.empty():\n",
        "    arr, labels = queue.get()\n",
        "    train_y.extend(labels)\n",
        "    if train_x is None:\n",
        "      train_x = arr\n",
        "    else:\n",
        "      train_x = np.vstack((train_x,arr))\n",
        "  return train_x , train_y\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0eRvH3QFo8kA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_testing_data():\n",
        "    threads_list = list()\n",
        "    test_x = None\n",
        "    queue = initialize_queue()\n",
        "    # iterate over num of threads to create\n",
        "    for thread_index in range(num_test_threads):\n",
        "        start_index = thread_index * batch_size\n",
        "        end_index = (thread_index + 1) * batch_size\n",
        "        file_batch = train_imgs[start_index:end_index]\n",
        "        thread = Thread(target =get_img_array, args=(file_batch, queue))\n",
        "        thread.start()\n",
        "        print(\"Thread: {}, start index: {}, end index: {}\".format(thread.name, start_index, end_index))\n",
        "        threads_list.append(thread)\n",
        "    \n",
        "    # join threads\n",
        "    for t in threads_list:\n",
        "        t.join()\n",
        "        print(\"Thread: {} joined\", t.name)\n",
        "    while not queue.empty():\n",
        "        arr= queue.get()\n",
        "        if test_x is None:\n",
        "            test_x = arr\n",
        "        else:\n",
        "            test_x = np.vstack((test_x, arr))\n",
        "    return test_x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sJs4OwYKpCjg",
        "colab_type": "code",
        "outputId": "ac3d4a38-b084-415d-9acf-7e78e8576d00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "cell_type": "code",
      "source": [
        "train_x, train_y = get_training_data()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thread: Thread-57, start index: 0, end index: 500\n",
            "Thread: Thread-58, start index: 500, end index: 1000\n",
            "Thread: Thread-59, start index: 1000, end index: 1500\n",
            "Thread: Thread-60, start index: 1500, end index: 2000\n",
            "Thread: Thread-61, start index: 2000, end index: 2500\n",
            "Thread: Thread-62, start index: 2500, end index: 3000\n",
            "Thread: Thread-63, start index: 3000, end index: 3500\n",
            "Thread: Thread-64, start index: 3500, end index: 4000\n",
            "Thread: Thread-65, start index: 4000, end index: 4500\n",
            "Thread: Thread-66, start index: 4500, end index: 5000\n",
            "Thread: Thread-67, start index: 5000, end index: 5500\n",
            "Thread: Thread-68, start index: 5500, end index: 6000\n",
            "Thread: Thread-69, start index: 6000, end index: 6500\n",
            "Thread: Thread-70, start index: 6500, end index: 7000\n",
            "Thread: Thread-71, start index: 7000, end index: 7500\n",
            "Thread: Thread-72, start index: 7500, end index: 8000\n",
            "Thread: Thread-73, start index: 8000, end index: 8500\n",
            "Thread: Thread-74, start index: 8500, end index: 9000\n",
            "Thread: Thread-75, start index: 9000, end index: 9500\n",
            "Thread: Thread-76, start index: 9500, end index: 10000\n",
            "Thread: Thread-77, start index: 10000, end index: 10500\n",
            "Thread: Thread-78, start index: 10500, end index: 11000\n",
            "Thread: Thread-79, start index: 11000, end index: 11500\n",
            "Thread: Thread-80, start index: 11500, end index: 12000\n",
            "Thread: Thread-81, start index: 12000, end index: 12500\n",
            "Thread: Thread-82, start index: 12500, end index: 13000\n",
            "Thread: Thread-83, start index: 13000, end index: 13500\n",
            "Thread: Thread-84, start index: 13500, end index: 14000\n",
            "Thread: Thread-85, start index: 14000, end index: 14500\n",
            "Thread: Thread-86, start index: 14500, end index: 15000\n",
            "Thread: Thread-87, start index: 15000, end index: 15500\n",
            "Thread: Thread-88, start index: 15500, end index: 16000\n",
            "Thread: Thread-89, start index: 16000, end index: 16500\n",
            "Thread: Thread-90, start index: 16500, end index: 17000\n",
            "Thread: Thread-91, start index: 17000, end index: 17500\n",
            "Thread: Thread-92, start index: 17500, end index: 18000\n",
            "Thread: Thread-93, start index: 18000, end index: 18500\n",
            "Thread: Thread-94, start index: 18500, end index: 19000\n",
            "Thread: Thread-95, start index: 19000, end index: 19500\n",
            "Thread: Thread-96, start index: 19500, end index: 20000\n",
            "Thread: Thread-97, start index: 20000, end index: 20500\n",
            "Thread: Thread-98, start index: 20500, end index: 21000\n",
            "Thread: Thread-99, start index: 21000, end index: 21500\n",
            "Thread: Thread-100, start index: 21500, end index: 22000\n",
            "Thread: Thread-101, start index: 22000, end index: 22500\n",
            "Thread: Thread-102, start index: 22500, end index: 23000\n",
            "Thread: Thread-103, start index: 23000, end index: 23500\n",
            "Thread: Thread-104, start index: 23500, end index: 24000\n",
            "Thread: Thread-105, start index: 24000, end index: 24500\n",
            "Thread: Thread-106, start index: 24500, end index: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GJch99aLskwE",
        "colab_type": "code",
        "outputId": "c87b3c7c-46f2-489d-9e59-67bdb30ea086",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print(train_x.shape)\n",
        "print(len(train_y))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(25000, 50, 50, 3)\n",
            "25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "clKoRcJyzU3C",
        "colab_type": "code",
        "outputId": "99d613a0-1999-4b18-8e96-d5afd460783b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1921
        }
      },
      "cell_type": "code",
      "source": [
        "test_x =get_testing_data()\n",
        "print(test_x.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thread: Thread-107, start index: 0, end index: 500\n",
            "Thread: Thread-108, start index: 500, end index: 1000\n",
            "Thread: Thread-109, start index: 1000, end index: 1500\n",
            "Thread: Thread-110, start index: 1500, end index: 2000\n",
            "Thread: Thread-111, start index: 2000, end index: 2500\n",
            "Thread: Thread-112, start index: 2500, end index: 3000\n",
            "Thread: Thread-113, start index: 3000, end index: 3500\n",
            "Thread: Thread-114, start index: 3500, end index: 4000\n",
            "Thread: Thread-115, start index: 4000, end index: 4500\n",
            "Thread: Thread-116, start index: 4500, end index: 5000\n",
            "Thread: Thread-117, start index: 5000, end index: 5500\n",
            "Thread: Thread-118, start index: 5500, end index: 6000\n",
            "Thread: Thread-119, start index: 6000, end index: 6500\n",
            "Thread: Thread-120, start index: 6500, end index: 7000\n",
            "Thread: Thread-121, start index: 7000, end index: 7500\n",
            "Thread: Thread-122, start index: 7500, end index: 8000\n",
            "Thread: Thread-123, start index: 8000, end index: 8500\n",
            "Thread: Thread-124, start index: 8500, end index: 9000\n",
            "Thread: Thread-125, start index: 9000, end index: 9500\n",
            "Thread: Thread-126, start index: 9500, end index: 10000\n",
            "Thread: Thread-127, start index: 10000, end index: 10500\n",
            "Thread: Thread-128, start index: 10500, end index: 11000\n",
            "Thread: Thread-129, start index: 11000, end index: 11500\n",
            "Thread: Thread-130, start index: 11500, end index: 12000\n",
            "Thread: Thread-131, start index: 12000, end index: 12500\n",
            "Thread: {} joined Thread-107\n",
            "Thread: {} joined Thread-108\n",
            "Thread: {} joined Thread-109\n",
            "Thread: {} joined Thread-110\n",
            "Thread: {} joined Thread-111\n",
            "Thread: {} joined Thread-112\n",
            "Thread: {} joined Thread-113\n",
            "Thread: {} joined Thread-114\n",
            "Thread: {} joined Thread-115\n",
            "Thread: {} joined Thread-116\n",
            "Thread: {} joined Thread-117\n",
            "Thread: {} joined Thread-118\n",
            "Thread: {} joined Thread-119\n",
            "Thread: {} joined Thread-120\n",
            "Thread: {} joined Thread-121\n",
            "Thread: {} joined Thread-122\n",
            "Thread: {} joined Thread-123\n",
            "Thread: {} joined Thread-124\n",
            "Thread: {} joined Thread-125\n",
            "Thread: {} joined Thread-126\n",
            "Thread: {} joined Thread-127\n",
            "Thread: {} joined Thread-128\n",
            "Thread: {} joined Thread-129\n",
            "Thread: {} joined Thread-130\n",
            "Thread: {} joined Thread-131\n",
            "(500, 50, 50, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 397, in _send_bytes\n",
            "    self._send(header)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 397, in _send_bytes\n",
            "    self._send(header)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 397, in _send_bytes\n",
            "    self._send(header)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 397, in _send_bytes\n",
            "    self._send(header)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 397, in _send_bytes\n",
            "    self._send(header)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 397, in _send_bytes\n",
            "    self._send(header)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "Traceback (most recent call last):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "FcjSg7Re1CgA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "dump_array('train_arr.pickle',train_x)\n",
        "dump_array('train_labels.pickle',train_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WQ6cFHeJ1U7E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dump_array('test_arr.pickle',test_x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5QfT03Gv1YUb",
        "colab_type": "code",
        "outputId": "464e99d1-0cc1-4e17-c591-cab5e3fad78d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"train_x shape\",train_x.shape)\n",
        "print(\"test_x shape\", test_x.shape)\n",
        "# convert train_y to np. array\n",
        "train_y = np.array(train_y)\n",
        "print(\"train_y.shape\", train_y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_x shape (25000, 50, 50, 3)\n",
            "test_x shape (500, 50, 50, 3)\n",
            "train_y.shape (25000, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vCijilyQ1c3E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_x = train_x/255\n",
        "test_x = test_x/255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9MyXRdAq1gGE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.utils import np_utils, to_categorical\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3CPpIKkh1kUn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N19B3XLB1nqb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.add(Conv2D(16, (3,3), input_shape=(50,50,3))) \n",
        "model.add(BatchNormalization(axis=3))\n",
        "model.add(Activation('relu'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1eViFrit1r6S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.add(MaxPooling2D(pool_size=(2,2),strides=2)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OJ52F7Tc1zQw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.add(Conv2D(16, (3,3)), ) \n",
        "model.add(BatchNormalization(axis=3))\n",
        "model.add(Activation('relu'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Nr-Ep73t15N0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.add(MaxPooling2D(pool_size=(2,2),strides=2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wk81j7jq19AK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.add(Conv2D(32, (3,3)))                     \n",
        "model.add(BatchNormalization(axis=3))\n",
        "model.add(Activation('relu'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ucm7wxSN2Cnu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.add(MaxPooling2D(pool_size=(2,2),strides=2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "esCU2Iza2FW-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.add(Conv2D(32, (3,3))) \n",
        "model.add(BatchNormalization(axis=3))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i2fSE8X72LUE",
        "colab_type": "code",
        "outputId": "6014b277-d688-4014-9170-223bf9460610",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        }
      },
      "cell_type": "code",
      "source": [
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-89-96a316d6dc9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_source_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 raise TypeError('All layers in a Sequential model '\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    412\u001b[0m                 \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m                 \u001b[0;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m                 \u001b[0;31m# Collect input shapes to build layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    325\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': expected min_ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_ndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m                                      str(K.ndim(x)))\n\u001b[0m\u001b[1;32m    328\u001b[0m             \u001b[0;31m# Check dtype.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input 0 is incompatible with layer flatten_2: expected min_ndim=3, found ndim=2"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "uGWxohF72Yqe",
        "colab_type": "code",
        "outputId": "1103b1cc-27e6-436e-c5fa-13c27b93eb82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "cell_type": "code",
      "source": [
        "print(onehot_encoded_arr[:2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-90-5c90ad7df750>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monehot_encoded_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'onehot_encoded_arr' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "Lvepwnou3JT1",
        "colab_type": "code",
        "outputId": "75939b10-046b-45bb-83b6-8468402e0ed5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "predictions = model.predict(test_x, batch_size=32, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500/500 [==============================] - 1s 2ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rr3tYTdS3NtJ",
        "colab_type": "code",
        "outputId": "76219eff-55f2-4e5f-e72f-d904fcf08bc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-92-5f15418b3570>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(self, line_length, positions, print_fn)\u001b[0m\n\u001b[1;32m   1250\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1251\u001b[0m             raise ValueError(\n\u001b[0;32m-> 1252\u001b[0;31m                 \u001b[0;34m'This model has not yet been built. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1253\u001b[0m                 \u001b[0;34m'Build the model first by calling build() '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m                 \u001b[0;34m'or calling fit() with some data. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling build() or calling fit() with some data. Or specify input_shape or batch_input_shape in the first layer for automatic build. "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "jt-yGYMd5Bom",
        "colab_type": "code",
        "outputId": "09050ca9-d7fe-4d24-e506-b1fe73c3b521",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!git init"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initialized empty Git repository in /content/.git/\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}